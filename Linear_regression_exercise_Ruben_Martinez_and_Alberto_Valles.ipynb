{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CS 5361/6361 Machine Learning**\n",
        "\n",
        "**Linear Regression Exercise**\n",
        "\n",
        "**Authors:**\n",
        "Ruben Martinez\n",
        "Alberto Valles"
      ],
      "metadata": {
        "id": "lE_HcewGOl2a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_qIYmagknS"
      },
      "source": [
        "**Exercise:**\n",
        "\n",
        "1.  Classify the MNIST dataset using linear regression by simply treating the class as a continuous variable and then rounding the results.  \n",
        "2.  Classify the MNIST dataset using linear regression converting the class to a 10-D vector using a one-hot representation.  \n",
        "3.  Repeat the previous step but now add the squares of the pixel intensities as features.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tmRqFbPHOcn6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dyAN72ox__f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.float32(x_train/255).reshape(x_train.shape[0],-1)\n",
        "x_test = np.float32(x_test/255).reshape(x_test.shape[0],-1)"
      ],
      "metadata": {
        "id": "6_wMj4olOiEj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJvGc4CqbR-n",
        "outputId": "71e3df0f-07eb-471d-eb5c-f8943ae025ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Classify the MNIST dataset using linear regression by simply treating the class as a continuous variable and then rounding the results. ***"
      ],
      "metadata": {
        "id": "l0G9w1py_8Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# create linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train) # train the model\n",
        "predictions = model.predict(x_train) # predict class labels in training data\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "IE8FHAaCw_kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fef20e6-5a00-4aae-b06a-9b3e0e4b817c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.192953  1.2161877 3.2152336 ... 6.724541  4.980859  6.311388 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rounding predictions to nearest integer to get the predicted classes\n",
        "predicted_classes = np.round(predictions).astype(int)\n",
        "\n",
        "\n",
        "# clip the predicted classes to be within the correct range of digits [0, 9]\n",
        "predicted_classes = np.clip(predicted_classes, 0, 9) # what this will do is replace negative predictions with 0 and replace predictions greater than 9 with 9\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = np.mean(predicted_classes == y_train)\n",
        "print(f'Accuracy (treating classes as continuous): {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "AklGRsAh_hQq",
        "outputId": "6929ad48-789e-4afb-f2f2-bed0407ace60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (treating classes as continuous): 23.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Classify the MNIST dataset using linear regression converting the class to a 10-D vector using a one-hot representation. ***"
      ],
      "metadata": {
        "id": "XpkPBAsx_zdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder # the class labels are converted to a 10-dimensional vector using OneHotEncoder module\n",
        "\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False) # create encoder\n",
        "\n",
        "# one-hot encode the class labels (0-9) into a 10-D vector\n",
        "y_train_one_hot = one_hot_encoder.fit_transform(y_train.reshape(-1, 1)) # (60000, 10)\n",
        "y_test_one_hot = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# fit the model with y_one_hot\n",
        "model.fit(x_train, y_train_one_hot)\n",
        "\n",
        "# make the predictions\n",
        "predictions = model.predict(x_train)\n",
        "\n",
        "# take the argmax of the predictions to convert them back to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = np.mean(predicted_classes == y_train)\n",
        "print(f'Accuracy (one-hot encoding): {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "d4zLIcTU_unN",
        "outputId": "440d6244-79e9-4ec9-8038-e2c757223bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (one-hot encoding): 85.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Repeat the previous step but now add the squares of the pixel intensities as features.***"
      ],
      "metadata": {
        "id": "fwK4CLDDBFTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features by adding the squared pixel intensities\n",
        "x_train_augmented = np.concatenate([x_train, x_train**2], axis=1)\n",
        "x_test_augmented = np.concatenate([x_test, x_test**2], axis=1)\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train_augmented, y_train_one_hot)\n",
        "\n",
        "# make the predicionts on the new train matrix\n",
        "predictions = model.predict(x_train_augmented)\n",
        "\n",
        "# take argmax of the predictions to convert them back to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = np.mean(predicted_classes == y_train)\n",
        "print(f'Accuracy (one-hot encoding with squares of pixel intensities): {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "O1gzPFPJBD3A",
        "outputId": "29736b91-dc7e-49d0-f1e2-14a54243841a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (one-hot encoding with squares of pixel intensities): 89.17%\n"
          ]
        }
      ]
    }
  ]
}